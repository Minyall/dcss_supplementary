{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["<br><br><font color=\"gray\">DOING COMPUTATIONAL SOCIAL SCIENCE<br>MODULE 8 <strong>PROBLEM SETS</strong></font>\n", "\n", "# <font color=\"#49699E\" size=40>MODULE 8 </font>\n", "\n", "\n", "# What You Need to Know Before Getting Started\n", "\n", "- **Every notebook assignment has an accompanying quiz**. Your work in each notebook assignment will serve as the basis for your quiz answers.\n", "- **You can consult any resources you want when completing these exercises and problems**. Just as it is in the \"real world:\" if you can't figure out how to do something, look it up. My recommendation is that you check the relevant parts of the assigned reading or search for inspiration on [https://stackoverflow.com](https://stackoverflow.com).\n", "- **Each problem is worth 1 point**. All problems are equally weighted.\n", "- **The information you need for each problem set is provided in the blue and green cells.** General instructions / the problem set preamble are in the blue cells, and instructions for specific problems are in the green cells. **You have to execute all of the code in the problem set, but you are only responsible for entering code into the code cells that immediately follow a green cell**. You will also recognize those cells because they will be incomplete. You need to replace each blank `\u25b0\u25b0#\u25b0\u25b0` with the code that will make the cell execute properly (where # is a sequentially-increasing integer, one for each blank).\n", "- Most modules will contain at least one question that requires you to load data from disk; **it is up to you to locate the data, place it in an appropriate directory on your local machine, and replace any instances of the `PATH_TO_DATA` variable with a path to the directory containing the relevant data**.\n", "- **The comments in the problem cells contain clues indicating what the following line of code is supposed to do.** Use these comments as a guide when filling in the blanks. \n", "- **You can ask for help**. \n", "\n", "Finally, remember that you do not need to \"master\" this content before moving on to other course materials, as what is introduced here is reinforced throughout the rest of the course. You will have plenty of time to practice and cement your new knowledge and skills.", "\n", "<div class='alert alert-block alert-danger'>", "As you complete this assignment, you may encounter variables that can be assigned a wide variety of different names. Rather than forcing you to employ a particular convention, we leave the naming of these variables up to you. During the quiz, submit an answer of 'USER_DEFINED' (without the quotation marks) to fill in any blank that you assigned an arbitrary name to. In most circumstances, this will occur due to the presence of a local iterator in a for-loop.", "</b>", "</div>"]}, {"cell_type": "markdown", "id": "greenhouse-bouquet", "metadata": {}, "source": ["## Package Imports"]}, {"cell_type": "code", "execution_count": 1, "id": "whole-coast", "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import networkx as nx\n", "import matplotlib as mpl\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "import pickle\n", "\n", "import random\n", "\n", "import numpy as np\n", "\n", "from dcss.networks import *\n", "\n", "import ndlib.models.ModelConfig as mc\n", "import ndlib.models.epidemics as ep\n", "from ndlib.utils import multi_runs\n", "\n", "%config Completer. use_jedi = False\n", "\n", "def simulation_overview(iteration_results, network, prop=True):\n", "    population_size = network.number_of_nodes()\n", "\n", "    trends = []\n", "    deltas = []\n", "\n", "    for iteration in iteration_results:\n", "        trends.append(iteration['node_count'])\n", "        deltas.append(iteration['status_delta'])\n", "\n", "    columns = ['Susceptible', 'Infected', 'Removed']\n", "\n", "    # trends DF\n", "    trends = pd.DataFrame(trends)\n", "    trends.columns = columns\n", "    if prop is True:\n", "        trends = trends.div(population_size)\n", "\n", "    # deltas DF\n", "    deltas = pd.DataFrame(deltas)\n", "    deltas.columns = columns\n", "\n", "    return trends, deltas\n", "\n", "\n", "def sir_model(network, beta, gamma, fraction_infected):\n", "    model = ep.SIRModel(network)\n", "\n", "    config = mc.Configuration()\n", "    config.add_model_parameter('beta', beta)\n", "    config.add_model_parameter('gamma', gamma)\n", "    config.add_model_parameter(\"fraction_infected\", fraction_infected)\n", "    \n", "    model.set_initial_status(config)\n", "    return model "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Problem 1:\n", "<div class=\"alert alert-block alert-info\">  \n", "For this assignment, we're going explore how simple contagions might spread through small networks of face-to-face contact. We'll start by generating a Watts-Strogratz Graph that will form the basis of the remainder of our investigation.\n", "</div>\n", "<div class=\"alert alert-block alert-success\">\n", "Using NetworkX, create a Watts-Strogratz Graph with p=0.15, n=500, and k=4. Instead of using keyword arguments, input your arguments as positional parameters. If you need some assistance as to which argument should go where, you can view the function's documentation by running the <code>?nx.watts_strogatz_graph</code> in a separate cell or consulting the NetworkX documentation directly. (The <code>?</code> command is very handy: it can be used to retrieve a docstring from any Python object)\n", "</div>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["G = nx.\u25b0\u25b01\u25b0\u25b0(\n", "    \u25b0\u25b02\u25b0\u25b0, \n", "    \u25b0\u25b03\u25b0\u25b0, \n", "    \u25b0\u25b04\u25b0\u25b0, \n", "    seed=42)\n", "\n", "pos = nx.nx_pydot.graphviz_layout(G)\n", "\n", "fig, ax = plt.subplots(figsize=(12, 12))\n", "nx.draw(\n", "    G, \n", "    pos,\n", "    ax=ax,\n", "    node_color=\"grey\",\n", "    edge_color=\"grey\",\n", "    node_size=100,\n", "    width=.5\n", ")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Problem 2:\n", "<div class=\"alert alert-block alert-info\">  \n", "In the previous assignment, we devoted a significant amount of time to exploring how four different measures of centrality (shortest-path, current flow, degree, and eigenvector) differ from one another. Intuitively, one might surmise that highly central nodes are more likely to spread simple contagions through a network more rapidly than less-central nodes. Thinking about this might cause one to wonder: \"Which of the various forms of centrality is the best predictor of a node's impact on diffusion processes?\"<br><br>\n", "In an attempt to provide a (limited, provisional) answer to this question, we'll use the centrality measures from last week: you can produce dictionaries of them by re-using some of your code from the previous assignment!\n", "</div>\n", "<div class=\"alert alert-block alert-success\">\n", "Create four centrality dictionaries (one each for shortest-path, current flow, degree, and eigenvector) for your Watts-Strogatz graph.\n", "</div>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Create dictionary of shortest-path betweenness centrality\n", "shortest_dict = nx.\u25b0\u25b01\u25b0\u25b0(\u25b0\u25b02\u25b0\u25b0)\n", "\n", "# Create dictionary of current-flow betweenness centrality\n", "current_dict = nx.\u25b0\u25b03\u25b0\u25b0(\u25b0\u25b04\u25b0\u25b0)\n", "\n", "# Create a dictionary of degree centralities\n", "deg_cent_dict = nx.\u25b0\u25b05\u25b0\u25b0(\u25b0\u25b06\u25b0\u25b0)\n", "\n", "# Create a dictionary of eigenvector centralities\n", "eigen_dict = nx.\u25b0\u25b07\u25b0\u25b0(\u25b0\u25b08\u25b0\u25b0, max_iter=1000)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Problem 3:\n", "<div class=\"alert alert-block alert-info\">  \n", "While having all of the centralities available can be useful, we're only interested in a small subset of the nodes that represent those in the network with the highest or lowest centrality scores. Rather than individually processing each list of the node centralities (which was what we did last week), it'll be more efficient to write a function that can handle multiple centrality dictionaries at the same time.\n", "</div>\n", "<div class=\"alert alert-block alert-success\">\n", "Finish writing this function that retrieves the `k` most or least central nodes from each centrality dictionary. Pay attention to the docstring (denoted on both sides by three sets of double quotation marks) for clues as to what purpose each parameter in the function serves.\n", "</div>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Write a function that retrieves the top most central nodes from each centrality dictionary\n", "def get_k_centrality(cents, top, K):\n", "    \"\"\"Takes in a list of centrality dictionaries and returns a list of \n", "    lists of nodes, representing either the top K or bottom K nodes as \n", "    measured by the centrality measure in question\n", "    \n", "    Args:\n", "        cents (list): A list of centrality dictionaries.\n", "        top (bool): If true, returns the nodes with the highest \n", "            centrality. If False, returns lowest.\n", "        K (int): Number of nodes to retrieve from each dictionary.\n", "        \n", "    Returns:\n", "        list: A list of lists of nodes.\n", "    \n", "    \"\"\"\n", "    \n", "    # Initialize an empty list for storing the node subset lists\n", "    final_list = []\n", "    \n", "    # iterate over the list of centralities passed to the function\n", "    \u25b0\u25b01\u25b0\u25b0 \u25b0\u25b02\u25b0\u25b0 \u25b0\u25b03\u25b0\u25b0 \u25b0\u25b04\u25b0\u25b0:\n", "        \n", "        # Retrieve the top K nodes, as measured by the given centrality, and store them in a list\n", "        # Note that the following list comprehension follows a similar pattern as the ones we used last week\n", "        cent_list = [e for e in sorted(centrality, key=lambda x: centrality[x], reverse=\u25b0\u25b05\u25b0\u25b0)[0:\u25b0\u25b06\u25b0\u25b0]]\n", "\n", "        # Add the resulting list of tuples to the overall list\n", "        final_list.append(cent_list)\n", "        \n", "    # Return the list of lists\n", "    return final_list"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Problem 4:\n", "<div class=\"alert alert-block alert-info\">  \n", "Now that our function is in place, we can take advantage of its ability to take in multiple centrality dictionaries at a time. The plan here is to get the top 10 nodes and bottom 10 nodes from each of the four centrality dictionaries, for a total of 8 iterations. We could do all 8 right off the bat, but unpacking the resulting lists all on one line is a messy affair; instead, we'll split the task into two discrete steps! \n", "</div>\n", "<div class=\"alert alert-block alert-success\">\n", "Use the 'get_k_centrality' function you completed in the previous question to get the top 10 nodes from each centrality dictionary. Using the printed top 10 lists as the basis for your answer, submit the ID of the node that appears in the first position (index 0) of three of the four centrality lists. \n", "</div>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["", "# Pass a list of each centrality dictionary to our function and unpack the returned value\n", "# **Make sure that the order of the dictionaries matches the order of the unpacking variables**\n", "top_shortest, top_current, top_degree, top_eigen = get_k_centrality(\n", "    [\u25b0\u25b01\u25b0\u25b0, \n", "     \u25b0\u25b02\u25b0\u25b0, \n", "     \u25b0\u25b03\u25b0\u25b0, \n", "     \u25b0\u25b04\u25b0\u25b0],\n", "    top=\u25b0\u25b05\u25b0\u25b0,\n", "    K=\u25b0\u25b06\u25b0\u25b0\n", ")\n", "\n", "\n", "print(top_shortest)\n", "print(top_current)\n", "print(top_degree)\n", "print(top_eigen)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Problem 5:\n", "<div class=\"alert alert-block alert-info\">  \n", "Now for the bottom 10.\n", "</div>\n", "<div class=\"alert alert-block alert-success\">\n", "Use your 'get_k_centrality' function to get the bottom 10 nodes from each centrality dictionary. Using the printed bottom 10 lists as the basis for your answer, submit the ID of the node that appears in the first position (index 0) of two of the four centrality lists. \n", "</div>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["", "# Pass a list of each centrality dictionary to our function and unpack the returned value\n", "# **Make sure that the order of the dictionaries matches the order of the unpacking variables**\n", "bottom_shortest, bottom_current, bottom_degree, bottom_eigen = get_k_centrality(\n", "    [\u25b0\u25b01\u25b0\u25b0, \n", "     \u25b0\u25b02\u25b0\u25b0, \n", "     \u25b0\u25b03\u25b0\u25b0, \n", "     \u25b0\u25b04\u25b0\u25b0],\n", "    top=\u25b0\u25b05\u25b0\u25b0,\n", "    K=\u25b0\u25b06\u25b0\u25b0\n", ")\n", "\n", "\n", "print(bottom_shortest)\n", "print(bottom_current)\n", "print(bottom_degree)\n", "print(bottom_eigen)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Problem 6:\n", "<div class=\"alert alert-block alert-info\">  \n", "Now we need a function that will allow us to put each infection set through its paces (using <code>multi_runs</code>). We'll approach this task in a similar manner as we did the previous function we built. Rather than tasking you with filling in many blanks, it's up to you to fill in just a single blank this time. The blank is for a built-in function that we'll use to randomly select 2 nodes from each list of nodes we pass to our function. The catch is that this built-in function isn't covered in the textbook or any of the other course material! It's up to you to examine the Python's official online documentation for the built-in <code>random</code> module and find the one you need.<br><br>\n", "Even though there won't be any other explicit questions to answer about the function we're building in this question, it's still a good idea to work through it line-by-line and make sure you understand what's happening at each step. We've held back on inserting explanatory comments; see if you can figure out each part of the code for yourself!\n", "</div>\n", "<div class=\"alert alert-block alert-success\">\n", "Examine the documentation for Python's built-in <code>random</code> module to find a function that randomly samples a number of objects from a list (or other iterable). Use this function to retrieve, at random, two items from each infect_set list generated as part of the function below. Submit the name of the function you used (and only the name) exactly as you used it in your code (you should not need to include any punctuation or special symbols).\n", "</div>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["", "def multi_run_infect_sets(sets, sir, runs, iterations):\n", "    \n", "    trend_list = []\n", "    \n", "    for infect_set in sets:\n", "        \n", "        # Create a list of 'infection sets', where each entry in the list is a list of two \n", "        # nodes randomly selected from those present in the 'infect_set' list\n", "        setlist = [random.\u25b0\u25b01\u25b0\u25b0(infect_set, k=2) for x in range(runs)]\n", "\n", "        trends = multi_runs(\n", "            sir, \n", "            execution_number=runs, \n", "            iteration_number=iterations, \n", "            infection_sets=setlist, \n", "            nprocesses=4)\n", "        \n", "        trend_list.append(trends)\n", "        \n", "    return trend_list\n", "    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Problem 7:\n", "<div class=\"alert alert-block alert-info\">  \n", "Now, we're going to initialize the SIR model and put it through its paces! Using the same custom function we used in the textbook, we'll create a SIR model based on our Watts-Strogatz Graph and with <code>beta</code> and <code>gamma</code> values of 0.1. You might notice that we've set the <code>fraction_infected</code> parameter to 1, which means that -- by default -- all of the nodes will start infected. Normally, such initial conditions wouldn't be very interesting from a network diffusion perspective, but in our case, the initial infection parameter is meaningless; we're going to be overriding the initially-infected nodes using the lists we prepared earlier.\n", "</div>\n", "<div class=\"alert alert-block alert-success\">\n", "After instantiating the SIR model, use the <code>multi_run_infect_sets</code> function to produce trend results for each of the 8 node lists (4 each for top and bottom). Each model should be run 500 times, and each run should consist of 200 iterations.\n", "</div>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%%capture\n", "sir_model_instance = sir_model(\u25b0\u25b01\u25b0\u25b0, beta=\u25b0\u25b02\u25b0\u25b0, gamma=\u25b0\u25b03\u25b0\u25b0, fraction_infected=1)\n", "\n", "top_shortest_trends, top_current_trends, top_degree_trends, top_eigen_trends = multi_run_infect_sets(\n", "    sets = [top_shortest, \n", "     top_current, \n", "     top_degree, \n", "     top_eigen], \n", "    sir = \u25b0\u25b04\u25b0\u25b0,\n", "    runs = \u25b0\u25b05\u25b0\u25b0,\n", "    iterations = \u25b0\u25b06\u25b0\u25b0\n", ")\n", "\n", "bottom_shortest_trends, bottom_current_trends, bottom_degree_trends, bottom_eigen_trends = multi_run_infect_sets(\n", "    [bottom_shortest, \n", "     bottom_current, \n", "     bottom_degree, \n", "     bottom_eigen], \n", "    \u25b0\u25b07\u25b0\u25b0,\n", "    \u25b0\u25b08\u25b0\u25b0,\n", "    \u25b0\u25b09\u25b0\u25b0\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Problem 8:\n", "<div class=\"alert alert-block alert-info\">  \n", "With all the preiminaries in place, we can move onto the final steps: visualization and interpretation. In this question, we're going to ask you to interpret the SIR trend visualizations produced by nodes from each of the top-ten centrality lists. Pay attention to the differences between them; do any of them <b>significantly</b> stand out from the others? If you're having trouble telling the difference between any of them, then they're probably not significantly different. If, conversely, one or two of the visualizations show a contagion spreading much more rapidly, then those centralities are likely more impactful than the others. \n", "</div>\n", "<div class=\"alert alert-block alert-success\">\n", "Select the statement that most closely matches your interpretation of the four visualizations below.\n", "<br><br>\n", "Note: the conclusions you draw for the purposes of this question should not be interpreted as a general truth about the relationship between diffusion dynamics and centrality in general. Your observations are specific to this network, are highly influenced by uncontrollable randomness, and should be interpreted as such. As a result of the randomness inherent to these models, it is possible that your interpretation will be correct, but will be graded as incorrect. If you feel that your interpretation was erroneously graded, please email screenshots of your visualizations from this question to Pierson. \n", "</div>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["", "top_trend_title_list = [\n", "    (top_shortest_trends, \"Top 5 Shortest-Path Betweenness Centrality\"),\n", "    (top_current_trends, \"Top 5 Current Flow Betweenness Centrality\"),\n", "    (top_degree_trends, \"Top 5 Degree Centrality\"),\n", "    (top_eigen_trends,\"Top 5 Eigenvector Centrality\"),\n", "]\n", "\n", "for trend, title in top_trend_title_list:\n", "    print(title)\n", "    visualize_trends(trend, network=G, return_data=False)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Problem 9:\n", "<div class=\"alert alert-block alert-info\">  \n", "Now, we'll do the same, but for the bottom ten nodes from each centrality measure. Since we're dealing with the bottom ten nodes here, 'more impactful' now corresponds with a significantly slower or less effective spread of the contagion.\n", "</div>\n", "<div class=\"alert alert-block alert-success\">\n", "Select the statement that most closely matches your interpretation of the four visualizations below.\n", "<br><br>\n", "Note: the conclusions you draw for the purposes of this question should not be interpreted as a general truth about the relationship between diffusion dynamics and centrality in general. Your observations are specific to this network, are highly influenced by uncontrollable randomness, and should be interpreted as such. As a result of the randomness inherent to these models, it is possible that your interpretation will be correct, but will be graded as incorrect. If you feel that your interpretation was erroneously graded, please email screenshots of your visualizations from this question to Pierson. \n", "</div>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["", "bottom_trend_title_list = [\n", "    (bottom_shortest_trends,\"Bottom 5 Shortest-Path Betweenness Centrality\"),\n", "    (bottom_current_trends,\"Bottom 5 Current Flow Betweenness Centrality\"),\n", "    (bottom_degree_trends,\"Bottom 5 Degree Centrality\"),\n", "    (bottom_eigen_trends,\"Bottom 5 Eigenvector Centrality\"),\n", "]\n", "\n", "for trend, title in bottom_trend_title_list:\n", "    print(title)\n", "    visualize_trends(trend, network=G, return_data=False)"]}], "metadata": {"metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.5"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": false, "sideBar": true, "skip_h1_title": false, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {}, "toc_section_display": true, "toc_window_display": false}, "varInspector": {"cols": {"lenName": 16, "lenType": 16, "lenVar": 40}, "kernels_config": {"python": {"delete_cmd_postfix": "", "delete_cmd_prefix": "del ", "library": "var_list.py", "varRefreshCmd": "print(var_dic_list())"}, "r": {"delete_cmd_postfix": ") ", "delete_cmd_prefix": "rm(", "library": "var_list.r", "varRefreshCmd": "cat(var_dic_list()) "}}, "types_to_exclude": ["module", "function", "builtin_function_or_method", "instance", "_Feature"], "window_display": false}}}, "nbformat": 4, "nbformat_minor": 4}
