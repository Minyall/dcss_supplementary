{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#49699E\" size=40>Text Similarity and Latent Semantic Space</font>\n",
    "# LEARNING OBJECTIVES\n",
    "# LEARNING MATERIALS\n",
    "# INTRODUCTION\n",
    "## Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.notebook_repr_html\", False)\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dcss.text import bigram_process, preprocess, bow_to_df, get_topic_word_scores\n",
    "from dcss.plotting import format_axes_commas, custom_seaborn\n",
    "from dcss.utils import sparse_groupby\n",
    "custom_seaborn()\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm', disable=['ner'])\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('../data/pickles/processed_sample_british_party_subset_hansards.pkl', 'rb') as fp:\n",
    "    preprocessed = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=.1,\n",
    "                                   min_df=3,\n",
    "                                   strip_accents='ascii')\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(preprocessed) \n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('../data/pickles/brit_hansards_sample_party_subset_count_matrix.pkl', 'rb') as fp:\n",
    "    count_matrix = pickle.load(fp)\n",
    "\n",
    "tfidf_scores = np.ravel(tfidf_matrix.sum(0))\n",
    "tfidf_scores = tfidf_scores/np.linalg.norm(tfidf_scores)\n",
    "term_counts = np.ravel(count_matrix.sum(0))\n",
    "term_counts = term_counts/np.linalg.norm(term_counts)\n",
    "vocabulary = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'Term': vocabulary, 'TFIDF': tfidf_scores, 'Count': term_counts})\n",
    "df.sort_values(by='TFIDF', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data=df.head(5000), x='Count', y='TFIDF', kind='hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(strip_accents='ascii', sublinear_tf=True)\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(preprocessed)\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Semantic Similarity and Clustering Documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('../data/pickles/sampled_british_hansard_speeches.pkl', 'rb') as fp:\n",
    "    speech_df = pickle.load(fp)\n",
    "    \n",
    "party_names = speech_df['party']\n",
    "tfidf_vocabulary = tfidf_vectorizer.get_feature_names()\n",
    "party_scores = sparse_groupby(party_names, tfidf_matrix, tfidf_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(party_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = Normalizer()\n",
    "party_scores_n = normalize.fit_transform(party_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix = party_scores_n @ party_scores_n.T\n",
    "sim_df = pd.DataFrame.sparse.from_spmatrix(sim_matrix).sparse.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fill_diagonal(sim_df.values, np.nan)\n",
    "sim_df.values[np.tril_indices(sim_df.shape[0], -1)] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df.index = party_scores.index\n",
    "sim_df.columns = party_scores.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sim_df.stack().nlargest(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sim_df.stack().nsmallest(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_scores_df = pd.DataFrame.sparse.from_spmatrix(party_scores_n)\n",
    "party_scores_df.index = party_scores.index\n",
    "party_scores_df.columns = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "for party in ['Labour','Liberal Democrat', 'Democratic Unionist Party', 'Plaid Cymru']:\n",
    "    print(party + '\\n')\n",
    "    print(party_scores_df.loc[party].nlargest(10))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLORING LATENT SEMANTIC SPACE WITH MATRIX DECOMPOSITION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Analysis (LSA) with Singular Value Decomposition (SVD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSA via SVD in sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa = TruncatedSVD(n_components=100, n_iter=6, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa = lsa.fit(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svs = lsa.singular_values_[:20]\n",
    "svs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_topics = pd.DataFrame(lsa.components_).T # transpose the dataframe so WORDS are in the rows\n",
    "column_names = [f'Topic {c}' for c in np.arange(1,101,1)]\n",
    "word_topics.columns = column_names\n",
    "\n",
    "word_topics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "word_topics.index = terms\n",
    "\n",
    "word_topics.sort_values(by='Topic 2', ascending = False)['Topic 2'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df = pd.DataFrame()\n",
    "\n",
    "compare_terms = ['england', 'scotland', 'wale', 'ireland']\n",
    "\n",
    "for i, term in enumerate(compare_terms):\n",
    "    scores = word_topics.loc[term].sort_values(ascending=False)\n",
    "    compare_df[i] = scores.index\n",
    "    compare_df[term] = scores.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_topics.loc['scotland'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_topic_word_scores(word_topics, 10, 'Topic 8')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSION\n",
    "## Key Points \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "333.9130554199219px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
